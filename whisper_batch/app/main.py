from __future__ import annotations

import datetime
import os
import shutil
import sys
import time
import traceback
import io
import pandas as pd
import json
from pathlib import Path
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv
from google.cloud import firestore, storage
from common_utils.class_types import WhisperFirestoreData
from common_utils.logger import logger

# â”€â”€ å¤–éƒ¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼å¤‰æ›ã€æ–‡å­—èµ·ã“ã—ã€è©±è€…åˆ†é›¢ã€çµæœçµåˆã®ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from whisper_batch.app.convert_audio import (
    convert_audio,
    check_audio_format,
)  # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’16kHzãƒ¢ãƒãƒ©ãƒ«WAVå½¢å¼ã«å¤‰æ›
from whisper_batch.app.transcribe import transcribe_audio  # éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—
from whisper_batch.app.diarize import diarize_audio  # è©±è€…åˆ†é›¢ã‚’å®Ÿè¡Œ
from whisper_batch.app.combine_results import (
    combine_results,
    read_json,
    save_dataframe,
)  # æ–‡å­—èµ·ã“ã—ã¨è©±è€…åˆ†é›¢ã®çµæœã‚’çµåˆ

# â”€â”€ .env èª­ã¿è¾¼ã¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æ—¢å­˜ã®ç’°å¢ƒå¤‰æ•°ã‚’ä¸Šæ›¸ã

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å ´æ‰€ã‚’åŸºæº–ã«ã™ã‚‹
BASE_DIR = Path(__file__).resolve().parent.parent
config_path = os.path.join(BASE_DIR, "config", ".env")
load_dotenv(config_path)

develop_config_path = os.path.join(BASE_DIR, "config_develop", ".env.develop")
if os.path.exists(develop_config_path):
    load_dotenv(develop_config_path)

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å ´æ‰€ã‚’åŸºæº–ã«ã—ã¦ã€BASEDIRã‚’ã¤ãã£ã¦ã€GOOGLE_APPLICATION_CREDENTIALSã«ã¤ã„ã¦ã‚‚çµ¶å¯¾ãƒ‘ã‚¹ã«ã™ã‚‹ã€‚
if str(BASE_DIR) not in os.environ["GOOGLE_APPLICATION_CREDENTIALS"]:
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = os.path.join(
        BASE_DIR, os.environ["GOOGLE_APPLICATION_CREDENTIALS"]
    )

# â”€â”€ ç’°å¢ƒå¤‰æ•°ï¼ˆæœªè¨­å®šæ™‚ã¯ KeyError ã‚’ç™ºç”Ÿã•ã›ã‚‹ï¼‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# COLLECTION ç’°å¢ƒå¤‰æ•°ã¯å¿…é ˆã€‚æœªè¨­å®šãªã‚‰èµ·å‹•æ™‚ä¾‹å¤–
try:
    COLLECTION = os.environ['COLLECTION']
except KeyError:
    raise RuntimeError(
        'Environment variable COLLECTION is required for whisper_batch'
    )
PROCESS_TIMEOUT_SECONDS: int = int(
    os.environ["PROCESS_TIMEOUT_SECONDS"]
)  # å‡¦ç†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰
DURATION_TIMEOUT_FACTOR: float = float(
    os.environ["AUDIO_TIMEOUT_MULTIPLIER"]
)  # éŸ³å£°é•·ã«åŸºã¥ãã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä¿‚æ•°
POLL_INTERVAL_SECONDS: int = int(
    os.environ["POLL_INTERVAL_SECONDS"]
)  # ã‚¸ãƒ§ãƒ–ç¢ºèªé–“éš”ï¼ˆç§’ï¼‰
HF_AUTH_TOKEN: str = os.environ["HF_AUTH_TOKEN"]  # Hugging Face APIãƒˆãƒ¼ã‚¯ãƒ³
DEVICE: str = os.environ["DEVICE"].lower()  # å‡¦ç†ãƒ‡ãƒã‚¤ã‚¹ï¼ˆ"cuda"ã¾ãŸã¯"cpu"ï¼‰
USE_GPU: bool = DEVICE == "cuda"  # GPUã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹
TMP_ROOT: Path = Path(os.environ["LOCAL_TMP_DIR"])  # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

# ãƒ•ã‚¡ã‚¤ãƒ«åãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
AUDIO_TEMPLATE = os.environ["WHISPER_AUDIO_BLOB"]
TRANS_TEMPLATE = os.environ["WHISPER_TRANSCRIPT_BLOB"]
DIAR_TEMPLATE = os.environ["WHISPER_DIARIZATION_BLOB"]
COMBINE_TEMPLATE = os.environ["WHISPER_COMBINE_BLOB"]


def _utcnow() -> datetime.datetime:
    """
    ç¾åœ¨ã®UTCæ™‚åˆ»ã‚’è¿”ã™

    Returns:
        datetime.datetime: ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ï¼ˆUTCï¼‰ä»˜ãã®ç¾åœ¨æ™‚åˆ»
    """
    return datetime.datetime.now(tz=datetime.timezone.utc)


def _mark_timeout_jobs(db: firestore.Client) -> None:
    """
    å‡¦ç†ä¸­ã®ã‚¸ãƒ§ãƒ–ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸã‚‚ã®ã‚’å¤±æ•—çŠ¶æ…‹ã«ãƒãƒ¼ã‚¯ã™ã‚‹

    Args:
        db (firestore.Client): Firestoreã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

    Note:
        - å‡¦ç†é–‹å§‹æ™‚åˆ»ã‹ã‚‰ä¸€å®šæ™‚é–“ï¼ˆåŸºæœ¬ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“ã‹éŸ³å£°é•·ã«æ¯”ä¾‹ã—ãŸæ™‚é–“ã®é•·ã„æ–¹ï¼‰çµŒéã—ãŸã‚¸ãƒ§ãƒ–ã‚’æ¤œå‡º
        - ãƒãƒƒãƒå‡¦ç†ã§è©²å½“ã‚¸ãƒ§ãƒ–ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã€Œå¤±æ•—ã€ã«æ›´æ–°
        - WhisperFirestoreDataãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼
    """
    now = _utcnow()
    col = db.collection(COLLECTION)
    batch = db.batch()
    updated = False
    for snap in col.where("status", "==", "processing").stream():
        data = snap.to_dict()
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’job_idã¨ã—ã¦è¿½åŠ 
        data["job_id"] = snap.id
        # WhisperFirestoreDataã§ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        try:
            firestore_data = WhisperFirestoreData(**data)
            # ä»¥é™ã¯ValidationãŒé€šã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
            started_at = firestore_data.process_started_at
            if not started_at:
                # process_started_atãŒNoneã®ã‚¸ãƒ§ãƒ–ã¯ç•°å¸¸çŠ¶æ…‹ã¨ã¿ãªã—ã€å¤±æ•—ã¨ã—ã¦ãƒãƒ¼ã‚¯
                batch.update(
                    snap.reference,
                    {
                        "status": "failed",
                        "error_message": "process_started_at is None",
                        "updated_at": firestore.SERVER_TIMESTAMP,
                    },
                )
                updated = True
                logger.warning(f"JOB {snap.id} âœ– process_started_atãŒNoneã®ãŸã‚å¤±æ•—ã¨ã—ã¦ãƒãƒ¼ã‚¯")
                continue

            # Firestoreã®Timestampå‹ã‚’é©åˆ‡ã«å‡¦ç†
            from google.cloud.firestore_v1._helpers import Timestamp

            if isinstance(started_at, Timestamp):
                started_at = started_at.to_datetime().replace(
                    tzinfo=datetime.timezone.utc
                )
            elif started_at.tzinfo is None:
                started_at = started_at.replace(tzinfo=datetime.timezone.utc)
            duration_ms = firestore_data.audio_duration_ms or 0
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“è¨ˆç®—
            timeout_sec = max(
                PROCESS_TIMEOUT_SECONDS,
                int(duration_ms / 1000 * DURATION_TIMEOUT_FACTOR),
            )
            if (now - started_at).total_seconds() > timeout_sec:
                batch.update(
                    snap.reference,
                    {
                        "status": "failed",
                        "error_message": "timeout",
                        "updated_at": firestore.SERVER_TIMESTAMP,
                    },
                )
                updated = True
        except Exception as e:
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ (job_id={snap.id}): {e}")
    if updated:
        batch.commit()


def _pick_next_job(db: firestore.Client) -> Optional[Dict[str, Any]]:
    """
    ã‚­ãƒ¥ãƒ¼ã‹ã‚‰æ¬¡ã®å‡¦ç†å¯¾è±¡ã‚¸ãƒ§ãƒ–ã‚’å–å¾—ã—ã¦ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã€Œå‡¦ç†ä¸­ã€ã«æ›´æ–°ã™ã‚‹

    Args:
        db (firestore.Client): Firestoreã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

    Returns:
        Optional[Dict[str, Any]]: ã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚­ãƒ¥ãƒ¼ãŒç©ºã®å ´åˆã¯Noneï¼‰

    Note:
        - ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã§å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ã‚¸ãƒ§ãƒ–ã®ç«¶åˆã‚’é˜²æ­¢
        - ä½œæˆæ—¥æ™‚ã®å¤ã„é †ã«1ä»¶å–å¾—ã—ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ã€Œprocessingã€ã«æ›´æ–°
        - ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’ã€Œjob_idã€ã‚­ãƒ¼ã«è¿½åŠ ã—ã¦ã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™
        - WhisperFirestoreDataãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼
    """

    @firestore.transactional
    def _txn(tx: firestore.Transaction) -> Optional[Dict[str, Any]]:
        col = db.collection(COLLECTION)
        docs = (
            col.where("status", "==", "queued")
            .order_by("created_at")
            .limit(1)
            .stream(transaction=tx)
        )
        docs = list(docs)
        if not docs:
            return None
        doc = docs[0]
        # Firestore ä¸Šã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
        tx.update(
            doc.reference,
            {
                "status": "processing",
                "process_started_at": firestore.SERVER_TIMESTAMP,
                "updated_at": firestore.SERVER_TIMESTAMP,
            },
        )
        # æˆ»ã‚Šå€¤ç”¨ãƒ‡ãƒ¼ã‚¿ã®çµ„ã¿ç«‹ã¦ï¼ˆæ›´æ–°å¾Œã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åæ˜ ï¼‰
        try:
            data = doc.to_dict()
            data["job_id"] = doc.id  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆIDã‚’ job_id ã¨ã—ã¦è¿½åŠ 
            # ã“ã“ã§ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ processing ã«ä¸Šæ›¸ã
            data["status"] = "processing"
            # WhisperFirestoreDataã§ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            firestore_data = WhisperFirestoreData(**data)
            # æ¤œè¨¼ãŒé€šã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’è¾æ›¸ã«æˆ»ã—ã¦è¿”ã™
            return dict(firestore_data.model_dump())
        except Exception as e:
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
            logger.error(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ (job_id={doc.id}): {e}")
            return None

    return _txn(db.transaction())


def _process_job(db: firestore.Client, job: Dict[str, Any]) -> None:
    """
    ã‚¸ãƒ§ãƒ–ã‚’å‡¦ç†ã™ã‚‹ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã€å¤‰æ›ã€æ–‡å­—èµ·ã“ã—ã€è©±è€…åˆ†é›¢ã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼‰

    Args:
        db (firestore.Client): Firestoreã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        job (Dict[str, Any]): å‡¦ç†å¯¾è±¡ã®ã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿

    Note:
        - WhisperFirestoreDataãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼
        - Cloud Storageã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        - éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’16kHzãƒ¢ãƒãƒ©ãƒ«WAVå½¢å¼ã«å¤‰æ›
        - Whisperãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã—
        - è©±è€…åˆ†é›¢ã®å®Ÿè¡Œ
        - æ–‡å­—èµ·ã“ã—ã¨è©±è€…åˆ†é›¢ã®çµæœã‚’çµåˆ
        - çµåˆçµæœã‚’Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        - å‡¦ç†çµæœã‚’Firestoreã«åæ˜ 
        - ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã¯ä¾‹å¤–ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¨˜éŒ²
        - ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¯å‡¦ç†å®Œäº†å¾Œã«å‰Šé™¤
    """
    # WhisperFirestoreDataã§ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚’è©¦ã¿ã‚‹
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã‚’é€šã—ã¦æ¤œè¨¼
        firestore_data = WhisperFirestoreData(**job)

        # æ¤œè¨¼ãŒé€šã£ãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
        job_id = firestore_data.job_id
        filename = firestore_data.filename
        bucket = firestore_data.gcs_bucket_name
        file_hash = firestore_data.file_hash
    except Exception as e:
        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼ã®ãƒ­ã‚°è¨˜éŒ²
        job_id = job.get("job_id", "<unknown>")
        msg = f"ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}"
        logger.error(f"JOB {job_id} âœ– {msg}")
        if job_id != "<unknown>":
            db.collection(COLLECTION).document(job_id).update(
                {
                    "status": "failed",
                    "error_message": msg,
                    "updated_at": firestore.SERVER_TIMESTAMP,
                }
            )
        return

    # ãƒ•ã‚¡ã‚¤ãƒ«æ‹¡å¼µå­ã¨ GCS ãƒ‘ã‚¹ã®çµ„ã¿ç«‹ã¦ - ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨
    ext = Path(filename).suffix.lstrip(".").lower()
    audio_blob = AUDIO_TEMPLATE.format(file_hash=file_hash, ext=ext)
    transcript_blob = TRANS_TEMPLATE.format(file_hash=file_hash)
    diarization_blob = DIAR_TEMPLATE.format(file_hash=file_hash)
    combine_blob = COMBINE_TEMPLATE.format(file_hash=file_hash)
    audio_uri = f"gs://{bucket}/{audio_blob}"
    transcript_uri = f"gs://{bucket}/{transcript_blob}"
    diarization_uri = f"gs://{bucket}/{diarization_blob}"  # è©±è€…åˆ†é›¢çµæœç”¨ã®URI
    combine_uri = f"gs://{bucket}/{combine_blob}"  # çµåˆçµæœç”¨ã®URI

    logger.info(f"JOB {job_id} â–¶ Start (audio: {audio_uri})")

    # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆï¼ˆã‚¸ãƒ§ãƒ–IDã¨ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å«ã‚€ä¸€æ„ã®åå‰ï¼‰
    tmp_dir = TMP_ROOT / f"job_{job_id}_{int(time.time())}"
    tmp_dir.mkdir(parents=True, exist_ok=True)
    storage_client = storage.Client()

    try:
        # Cloud Storageã‹ã‚‰éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        local_audio = tmp_dir / audio_blob
        storage_client.bucket(bucket).blob(audio_blob).download_to_filename(local_audio)
        logger.info(f"JOB {job_id} â¤µ Downloaded â†’ {local_audio}")

        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’16kHzãƒ¢ãƒãƒ©ãƒ«WAVå½¢å¼ã«å¤‰æ›ï¼ˆã¾ãŸã¯æ—¢ã«é©åˆ‡ãªå½¢å¼ãªã‚‰ã‚³ãƒ”ãƒ¼ï¼‰
        wav_path = tmp_dir / f"{file_hash}_16k_mono.wav"

        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ—¢ã«16kHzãƒ¢ãƒãƒ©ãƒ«WAVã‹ç¢ºèª
        is_optimized_format = check_audio_format(str(local_audio))

        if is_optimized_format:
            # æ—¢ã«é©åˆ‡ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãªã‚‰ã‚³ãƒ”ãƒ¼ã™ã‚‹ã ã‘
            shutil.copy2(str(local_audio), str(wav_path))
            logger.info(f"JOB {job_id} ğŸ§ Format already 16kHz mono WAV â†’ {wav_path}")
        else:
            # å¤‰æ›ãŒå¿…è¦ãªå ´åˆã¯é€šå¸¸é€šã‚Šå¤‰æ›
            convert_audio(str(local_audio), str(wav_path), use_gpu=USE_GPU)
            logger.info(f"JOB {job_id} ğŸ§ Converted â†’ {wav_path}")

        # Whisperãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ–‡å­—èµ·ã“ã—
        transcript_local = tmp_dir / transcript_blob
        transcribe_audio(
            str(wav_path), str(transcript_local), device=DEVICE, job_id=job_id
        )
        logger.info(f"JOB {job_id} âœ Transcribed â†’ {transcript_local}")

        # è©±è€…æ•°ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ–‡å­—åˆ—å‹ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§æ•´æ•°ã«å¤‰æ›ï¼‰
        # NUM_SPEAKERS ã®å®‰å…¨ãƒ‘ãƒ¼ã‚¹
        try:
            num_speakers = int(os.getenv('NUM_SPEAKERS')) \
                if os.getenv('NUM_SPEAKERS') else None
        except ValueError:
            num_speakers = None
        min_speakers = int(job.get("min_speakers", 1))
        max_speakers = int(job.get("max_speakers", 1))

        # è©±è€…åˆ†é›¢ã¾ãŸã¯ã‚·ãƒ³ãƒ—ãƒ«ãªè©±è€…æƒ…å ±ã®ç”Ÿæˆ
        diarization_local = tmp_dir / "speaker.json"

        # å˜ä¸€è©±è€…ã‹ã©ã†ã‹ã‚’ç¢ºèª
        is_single_speaker = num_speakers == 1 or (
            num_speakers is None and max_speakers == 1
        )

        if is_single_speaker:
            # å˜ä¸€è©±è€…ã®å ´åˆã€è©±è€…åˆ†é›¢ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç°¡æ˜“çš„ãªè©±è€…æƒ…å ±ã‚’ç”Ÿæˆ
            create_single_speaker_json(str(transcript_local), str(diarization_local))
            logger.info(f"JOB {job_id} ğŸ‘¤ Single speaker mode â†’ {diarization_local}")
        else:
            # è¤‡æ•°è©±è€…ã®å ´åˆã¯é€šå¸¸é€šã‚Šè©±è€…åˆ†é›¢ã‚’å®Ÿè¡Œ
            diarize_audio(
                str(wav_path),
                str(diarization_local),
                hf_auth_token=HF_AUTH_TOKEN,  # Hugging Faceèªè¨¼ãƒˆãƒ¼ã‚¯ãƒ³
                num_speakers=num_speakers,
                min_speakers=min_speakers,
                max_speakers=max_speakers,
                device=DEVICE,
                job_id=job_id,
            )
            logger.info(f"JOB {job_id} ğŸ‘¥ Diarized â†’ {diarization_local}")

        # æ–‡å­—èµ·ã“ã—ã¨è©±è€…åˆ†é›¢ã®çµæœã‚’çµåˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªè©±è€…æƒ…å ±ã®å ´åˆã‚‚åŒæ§˜ï¼‰
        combine_local = tmp_dir / "combine.json"
        combine_results(str(transcript_local), str(diarization_local), str(combine_local))
        logger.info(f"JOB {job_id} ğŸ”— Combined â†’ {combine_local}")

        # æ–‡å­—èµ·ã“ã—çµæœã‚’Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        storage_client.bucket(bucket).blob(transcript_blob).upload_from_filename(
            transcript_local
        )
        logger.info(f"JOB {job_id} â¬† Uploaded transcription â†’ {transcript_uri}")

        # è©±è€…åˆ†é›¢çµæœã‚’Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        storage_client.bucket(bucket).blob(diarization_blob).upload_from_filename(diarization_local)
        logger.info(f"JOB {job_id} â¬† Uploaded diarization result â†’ {diarization_uri}")

        # çµåˆçµæœã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        storage_client.bucket(bucket).blob(combine_blob).upload_from_filename(combine_local)
        logger.info(f"JOB {job_id} â¬† Uploaded combine result â†’ {combine_uri}")

        # å‡¦ç†æˆåŠŸã‚’Firestoreã«åæ˜ ã™ã‚‹å‰ã«ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèª
        job_doc = db.collection(COLLECTION).document(job_id).get()
        if not job_doc.exists:
            logger.error(
                f"JOB {job_id} âœ– ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
            )
        else:
            current_status = job_doc.to_dict().get("status", "")
            if current_status != "processing":
                logger.error(
                    f"JOB {job_id} âœ– ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ processing ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆ{current_status}ï¼‰ã€‚æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
                )
            else:
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ"processing"ã®å ´åˆã®ã¿æ›´æ–°
                db.collection(COLLECTION).document(job_id).update(
                    {
                        "status": "completed",
                        "process_ended_at": firestore.SERVER_TIMESTAMP,
                        "updated_at": firestore.SERVER_TIMESTAMP,
                    }
                )
                logger.info(f"JOB {job_id} âœ” Completed")

    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®å‡¦ç†
        err = str(e)
        logger.error(f"JOB {job_id} âœ– Failed: {err}\n{traceback.format_exc()}")

        # Firestoreã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
        job_doc = db.collection(COLLECTION).document(job_id).get()

        if not job_doc.exists:
            logger.error(
                f"JOB {job_id} âœ– ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
            )
        else:
            job_data = job_doc.to_dict() or {}
            current_status = job_data.get("status", "")

            if current_status != "processing":
                logger.error(
                    f"JOB {job_id} âœ– ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã«ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ processing ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆ{current_status}ï¼‰ã€‚æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚"
                )
            else:
                # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãŒ"processing"ã®å ´åˆã®ã¿æ›´æ–°
                # æ›´æ–°ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                update_data = {
                    "status": "failed",
                    "error_message": err,
                    "process_ended_at": firestore.SERVER_TIMESTAMP,
                    "updated_at": firestore.SERVER_TIMESTAMP,
                }

                # process_started_atãŒãªã„å ´åˆã¯è¿½åŠ ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆåˆ¤å®šã®ãŸã‚ï¼‰
                if not job_data.get("process_started_at"):
                    update_data["process_started_at"] = firestore.SERVER_TIMESTAMP

                # æ›´æ–°ã‚’å®Ÿè¡Œ
                db.collection(COLLECTION).document(job_id).update(update_data)
                logger.error(f"JOB {job_id} âœ– å‡¦ç†å¤±æ•—ã‚’è¨˜éŒ²ã—ã¾ã—ãŸ: {err}")

    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤ï¼ˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‰Šé™¤ã‚’è©¦ã¿ã‚‹ï¼‰
        shutil.rmtree(tmp_dir, ignore_errors=True)


def create_single_speaker_json(transcription_path, output_path):
    """
    å˜ä¸€è©±è€…ç”¨ã®è©±è€…æƒ…å ±JSONã‚’ç”Ÿæˆã™ã‚‹

    Args:
        transcription_path (str): æ–‡å­—èµ·ã“ã—çµæœJSONã®ãƒ‘ã‚¹
        output_path (str): å‡ºåŠ›ã™ã‚‹è©±è€…æƒ…å ±JSONã®ãƒ‘ã‚¹
    """
    try:
        # æ–‡å­—èµ·ã“ã—çµæœã‚’èª­ã¿è¾¼ã‚€
        transcription_df = read_json(transcription_path)

        # å˜ä¸€è©±è€…ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        speaker_data = []
        for _, row in transcription_df.iterrows():
            speaker_data.append(
                {
                    "start": row["start"],
                    "end": row["end"],
                    "speaker": "SPEAKER_01",  # å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’åŒä¸€è©±è€…ã«å‰²ã‚Šå½“ã¦
                }
            )

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«å¤‰æ›ã—ã¦ä¿å­˜
        speaker_df = pd.DataFrame(speaker_data)
        save_dataframe(speaker_df, output_path)

        logger.info(f"å˜ä¸€è©±è€…JSONã‚’ç”Ÿæˆã—ã¾ã—ãŸ: {output_path}")

    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼æ™‚ã¯æœ€å°é™ã®è©±è€…æƒ…å ±ã‚’ç”Ÿæˆï¼ˆç©ºã®JSONé…åˆ—ï¼‰
        logger.error(f"å˜ä¸€è©±è€…JSONã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        if output_path.startswith("gs://"):
            # GCSã®å ´åˆ
            path_without_prefix = output_path[5:]
            bucket_name, blob_path = path_without_prefix.split("/", 1)

            storage_client = storage.Client()
            bucket = storage_client.bucket(bucket_name)
            blob = bucket.blob(blob_path)

            blob.upload_from_string("[]", content_type="application/json")
        else:
            # ãƒ­ãƒ¼ã‚«ãƒ«ã®å ´åˆ
            os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)
            with open(output_path, "w") as f:
                json.dump([], f)


def main() -> None:
    """
    ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—å‡¦ç†

    Note:
        - Firestoreã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        - ç„¡é™ãƒ«ãƒ¼ãƒ—ã§ä»¥ä¸‹ã®å‡¦ç†ã‚’ç¹°ã‚Šè¿”ã™ï¼š
          1. ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ãŸã‚¸ãƒ§ãƒ–ã‚’ãƒãƒ¼ã‚¯
          2. æ¬¡ã®ã‚¸ãƒ§ãƒ–ã‚’å–å¾—ã—ã¦å‡¦ç†
          3. ã‚¸ãƒ§ãƒ–ãŒãªã‘ã‚Œã°ä¸€å®šæ™‚é–“å¾…æ©Ÿ
        - Ctrl+Cã§çµ‚äº†å¯èƒ½
        - äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ã¯è¨˜éŒ²ã—ã¦å¾…æ©Ÿå¾Œã«å†è©¦è¡Œ
    """
    db = firestore.Client()
    while True:
        try:
            _mark_timeout_jobs(db)  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¸ãƒ§ãƒ–ã‚’ãƒãƒ¼ã‚¯
            job = _pick_next_job(db)  # æ¬¡ã®ã‚¸ãƒ§ãƒ–ã‚’å–å¾—
            if job:
                _process_job(db, job)  # ã‚¸ãƒ§ãƒ–ã‚’å‡¦ç†
            else:
                logger.info("ã‚­ãƒ¥ãƒ¼ãŒç©ºã§ã™ã€‚å¾…æ©Ÿâ€¦")
                time.sleep(POLL_INTERVAL_SECONDS)  # ä¸€å®šæ™‚é–“å¾…æ©Ÿ
        except KeyboardInterrupt:
            logger.info("SIGINT å—ä¿¡ã€‚ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’çµ‚äº†ã—ã¾ã™")
            break
        except Exception as e:
            logger.error(f"Main loop error: {e}\n{traceback.format_exc()}")
            time.sleep(POLL_INTERVAL_SECONDS)  # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ä¸€å®šæ™‚é–“å¾…æ©Ÿ


def run_batch_job():
    """
    ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®Ÿè¡Œã™ã‚‹å‡¦ç†ã‚’é›†ç´„ã—ãŸé–¢æ•°
    
    Returns:
        bool: å‡¦ç†ãŒæˆåŠŸã—ãŸã‹ã©ã†ã‹
    """
    # GCPã®ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã¯JOB_IDã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
    job_id = os.environ.get("JOB_ID")
    if not job_id:
        logger.error("JOB_ID ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False
        
    db = firestore.Client()
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’"processing"ã«æ›´æ–°
    doc_ref = db.collection(COLLECTION).document(job_id)
    try:
        doc_ref.update({
            "status": "processing",
            "process_started_at": firestore.SERVER_TIMESTAMP,
            "updated_at": firestore.SERVER_TIMESTAMP,
        })
        logger.info(f"JOB {job_id} â–¶ Status updated to 'processing'")
    except Exception as e:
        logger.error(f"JOB {job_id} âœ– Failed to update status: {str(e)}")
        return False
    
    # Firestoreã‹ã‚‰ã‚¸ãƒ§ãƒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    job_doc = doc_ref.get()
    if not job_doc.exists:
        logger.error(f"JOB {job_id} âœ– Job document not found in Firestore")
        return False
        
    job_data = job_doc.to_dict()
    job_data["job_id"] = job_id  # job_idã‚’ãƒ‡ãƒ¼ã‚¿ã«è¿½åŠ 
    try:
        # ã‚¸ãƒ§ãƒ–ã‚’å‡¦ç†
        _process_job(db, job_data)
        return True
    except Exception as e:
        # ä¾‹å¤–æ™‚ã¯ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’"failed"ã«æ›´æ–°
        error_message = f"Exception in batch job: {str(e)}\n{traceback.format_exc()}"
        logger.error(f"JOB {job_id} âœ– {error_message}")
        doc_ref.update({
            "status": "failed",
            "error_message": str(e),
            "process_ended_at": firestore.SERVER_TIMESTAMP,
            "updated_at": firestore.SERVER_TIMESTAMP,
        })
        return False

if __name__ == "__main__":
    # ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã‹ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã‹ã‚’åˆ¤æ–­
    if os.environ.get("JOB_ID"):
        # ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®Ÿè¡Œ
        try:
            success = run_batch_job()
            if not success:
                sys.exit(1)  # å‡¦ç†å¤±æ•—æ™‚ã¯éã‚¼ãƒ­ã§çµ‚äº†
        except Exception as e:
            logger.critical(f"Fatal error in batch job: {str(e)}", exc_info=True)
            sys.exit(1)  # ä¾‹å¤–ç™ºç”Ÿæ™‚ã‚‚éã‚¼ãƒ­ã§çµ‚äº†
    else:
        # ãƒ¯ãƒ¼ã‚«ãƒ¼ãƒ¢ãƒ¼ãƒ‰ã¨ã—ã¦å®Ÿè¡Œ
        main()
